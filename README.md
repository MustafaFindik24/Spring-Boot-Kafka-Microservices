# ğŸ¯ Apache Kafka Nedir?

Kafka, herÅŸeyin veri olarak kabul edildiÄŸi bu dÃ¶nemde bize verilerin yÃ¶netimini kolaylaÅŸtÄ±ran, publish-subscriber tabanlÄ± bir daÄŸÄ±tÄ±k veri akÄ±ÅŸÄ± platformudur.

![image](https://user-images.githubusercontent.com/91599453/227554058-9150341a-4941-4d5b-bc5e-126084219ad5.png)

GeliÅŸmiÅŸ sistemlerin birbirleriyle yaptÄ±ÄŸÄ± veri akÄ±ÅŸÄ± sonucunda veri kaybÄ±nÄ±n Ã¶nlenmesi, verilerin en hÄ±zlÄ± ve sistemi en az etkileyecek ÅŸekilde gÃ¶nderimi konusunda Kafka bize kolaylÄ±k saÄŸlamaktadÄ±r. Veriler diske yazÄ±lÄ±r ve kafka cluster'larda kopyasÄ± oluÅŸturularak veri kaybÄ±nÄ±n Ã¶nÃ¼ne geÃ§er. GerÃ§ek zamana yakÄ±n bir ÅŸekilde veri akÄ±ÅŸÄ±nÄ± saÄŸlar. Ã–lÃ§eklenebilir olduÄŸundan sistemde herhangi bir kesinti yaÅŸanmaksÄ±zÄ±n sistemlerde aksama meydana gelmez. Uygulamalar arasÄ± platform desteÄŸi saÄŸlar, bu sayede farklÄ± platformlar arasÄ±nda veri akÄ±ÅŸÄ± saÄŸlanmÄ±ÅŸ olur. 

# ğŸ“Œ Kafka Terminolojileri 

- Publisher : Veriyi gÃ¶nderen uygulamadÄ±r.

- Subscriber: Veriyi alan uygulamadÄ±r.

- Producer  : Bir veya birden fazla topice veri gÃ¶nderen birimdir.

- Consumer  : Bir veya birden fazla topicten veri okuyabilen birimdir.

- Topic     : Verilerin saklandÄ±ÄŸÄ± ve listelenebildiÄŸi bir kategori. VeritabanÄ±ndaki tablonun karÅŸÄ±lÄ±ÄŸÄ±dÄ±r.

- Partition : Veriyi tek bir yerde tutmak yerine farklÄ± dizinlerde tutmak performans ve veri kaybÄ±nÄ±n Ã¶nlenmesi aÃ§Ä±sÄ±ndan daha verimlidir. Topicler bir veya birden fazla ÅŸekilde parÃ§alardan (partition) oluÅŸurlar. Bu ÅŸekilde bir topicdeki veriler birden fazla sunucuda tutulabilir.

![image](https://user-images.githubusercontent.com/91599453/227864593-bae505df-8f22-41ae-abe9-1906c0996cbf.png)

- Broker    : Birden fazla partitionÄ±n birlikte oluÅŸturduÄŸu yapÄ±ya broker denir. Her bir Kafka sunucusuna (cluster) broker adÄ± verilir.

- Cluster   : Kafka daÄŸÄ±tÄ±k bir sistemdir. Birden fazla sunucudan oluÅŸur ve verileri farklÄ± sunucularda (cluster) tutabilir. Bu sayede daha hÄ±zlÄ± ve daha performanslÄ± veri akÄ±ÅŸÄ± saÄŸlanÄ±r.

- Offset    : KafkanÄ±n bir subscriber (consumer) gÃ¶nderdiÄŸi son mesajÄ±n numarasÄ±dÄ±r.

- Zookeeper : Kafka cluster'da topic ve verilerin listesini saklayan, nodelarÄ±n durumunu izleyen; uygulamaya bir broker eklendiÄŸi zaman veya Ã§alÄ±ÅŸmadÄ±ÄŸÄ±, bir problem oluÅŸtuÄŸu zaman publisher (producer) ve subscriber (consumer) bilgilendiren bir servis olarak tanÄ±mlanabilir. Kafka, metadata bilgilerini saklamak iÃ§in Zookeeper'Ä± kullanmaktadÄ±r. Bu sebeple Kafka ile kullanÄ±mÄ± zorunludur.

# ğŸ“Œ Apache Kafka ve Spring Boot

ğŸ¯ producer-service


* Bir Spring Boot projesi oluÅŸturup Kafka kullanÄ±mÄ± iÃ§in pom.xml dosyamÄ±zÄ±n iÃ§erisine Kafka dependency eklenir.

``` xml

<dependency>
	<groupId>org.springframework.kafka</groupId>
	<artifactId>spring-kafka</artifactId>
</dependency>

```

* Kafka'yÄ± Docker Ã¼zerinde Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z. Bunun iÃ§in docker-compose dosyasÄ± oluÅŸturup gerekli imagelarÄ± ekleyip ilgili containerlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±yoruz.

```yml

version: '3.8'
services:

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:5.4.9
    restart: always
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - my-network

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:6.0.9
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_ADVERTISED_HOST_NAME:
    networks:
      - my-network

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: always
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKER_CONNECT: kafka:29092
    networks:
      - my-network

networks:
  my-network:
    driver: bridge
    
```

* Kafkada producer ve consumer sÃ¼reÃ§lerinden bahsetmiÅŸtik. Tek bir projede bÃ¼tÃ¼n sÃ¼reÃ§leri kontrol etmek yerine hem producer hem de consumer iÃ§in farklÄ± projeler oluÅŸturup microservice mimarisi mantÄ±ÄŸÄ±na gÃ¶re uygulamamÄ±zÄ± Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z. 

application.properties dosyamÄ±zda server portunu, logging iÃ§in log seviyesini ve kafkanÄ±n adresini, deÄŸerini ve topic ismini belirtiyoruz.
```properties
server.port=2333

logging.level.root= INFO

mustafafindik.kafka.address = 127.0.0.1:9092
mustafafindik.kafka.group.id = kafka-group
mustafafindik.kafka.topic = kafka-topic
```

* Ä°lk olarak producer-service projemizde veriyi Ã¼retip kafkaya atamak iÃ§in bazÄ± configurationlar gerekli. Bunu config package Ä± altÄ±nda oluÅŸturup Spring IOC containerÄ±na atamak iÃ§in bean olarak belirtiyoruz. application.properties sÄ±nÄ±fÄ±nda belirttiÄŸimiz value larÄ± ekleyip veriyi gÃ¶ndermek iÃ§in kafkaTemplate sÄ±nÄ±fÄ±nÄ±, veriyi Ã¼retmek iÃ§inde producerFactory sÄ±nÄ±fÄ±nÄ± belirtiyoruz.

```java
@Configuration
public class KafkaConfiguration {

    @Value("${mustafafindik.kafka.address}")
    private String kafkaAddress;
    
    @Value("${mustafafindik.kafka.group.id}")
    private String groupId;
    
    @Bean
    public KafkaTemplate<String, User> kafkaTemplate(){
        return new KafkaTemplate<>(producerFactory());
    }
    @Bean
    public ProducerFactory producerFactory(){
        Map<String,Object> producer = new HashMap<>();
        producer.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaAddress);
        producer.put(JsonSerializer.ADD_TYPE_INFO_HEADERS,true);
        producer.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        producer.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,JsonSerializer.class);
        return new DefaultKafkaProducerFactory(producer);
    }
}
```
* Modelimizi oluÅŸturup Kafka'ya veri gÃ¶nderimini saÄŸlamak iÃ§in KafkaProducer sÄ±nÄ±fÄ±nÄ± oluÅŸturduk. KafkaTemplate sÄ±nÄ±fÄ±nÄ± inject edip send() metoduyla veri gÃ¶nderimi iÃ§in ortam hazÄ±rlandÄ±.

```java
@Component
public class KafkaProducer {
    
    private final KafkaTemplate<String, User> kafkaTemplate;

    public KafkaProducer(KafkaTemplate<String, User> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    public void userProducer(User user){
        kafkaTemplate.send("${mustafafindik.kafka.topic}", UUID.randomUUID().toString(),user);
    }
}
```
* Service sÄ±nÄ±fÄ±mÄ±zÄ± oluÅŸturup KafkaProducer sÄ±nÄ±fÄ±nÄ± inject edip Kafka'ya veri gÃ¶nderimi iÃ§in metot oluÅŸturduk ve KafkaProducer sÄ±nÄ±fÄ±ndaki metodu kullandÄ±k.

```java
@Service
public class UserServiceImpl implements UserService{
    private final KafkaProducer kafkaProducer;

    public UserServiceImpl(KafkaProducer kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }
    @Override
    public void createUser(User user) {
        User saveUser = new User();
        saveUser.setUsername(saveUser.getUsername());
        saveUser.setPassword(saveUser.getPassword());
        kafkaProducer.userProducer(saveUser);
    }
}
```

* Controller sÄ±nÄ±fÄ±nda post isteÄŸi iÃ§in metot oluÅŸturduk ve logunu gÃ¶rebilmek iÃ§in console ekranÄ±na info bastÄ±rdÄ±k.

```java
@Slf4j
@RestController
@RequestMapping("/message")
public class UserController {

    @Value("${mustafafindik.kafka.topic}")
    private String topic;
    private final KafkaTemplate<String, User> kafkaTemplate;

    public UserController(KafkaTemplate<String, User> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    @PostMapping
    public void sendMessage(@RequestBody User user){
        kafkaTemplate.send(topic, UUID.randomUUID().toString(), user);
        log.info("User class send to the queue : " + user);
    }
}
```

* localhost:2333/message pathine JSON verisi olarak post isteÄŸi attÄ±ktan sonra console ekranÄ±nda log gÃ¶rÃ¼lebilir.

![image](https://user-images.githubusercontent.com/91599453/227879283-fc652d82-fd18-4f16-86e0-0736a3658b98.png)

* Docker-compose dosyamÄ±zÄ± Ã§alÄ±ÅŸtÄ±rmÄ±ÅŸtÄ±k. http://localhost:9000/ giderek ayaÄŸa kaldÄ±rdÄ±ÄŸÄ±mÄ±z Kafdrop uygulamasÄ±nÄ± ve aÅŸaÄŸÄ±da oluÅŸturduÄŸumuz topic i gÃ¶rebiliriz.

![image](https://user-images.githubusercontent.com/91599453/227879727-8d6305d7-eb8a-46d2-91a2-b04a2b51e7b6.png)

* Ä°lgili topic e girip mesajlarÄ± listele dedikten sonra attÄ±ÄŸÄ±mÄ±z post isteklerini bazÄ± metadatalarÄ±nda belirtilip listelendiÄŸini gÃ¶rebiliriz.

![image](https://user-images.githubusercontent.com/91599453/227880270-406e8995-e1c4-4ffa-9cac-0893854a22d6.png)

producer-service projemizin yaptÄ±ÄŸÄ± iÅŸlem bu kadar. Åimdi consumer-service projemizi inceleyelim.

ğŸ¯ consumer-service

* Kafka'daki veriyi dinleyip gelen veriyi veritabanÄ±na kaydedeceÄŸiz. Bunun iÃ§in Ã¶ncelikle bir Spring Boot projesi oluÅŸturup ilgili dependencylerimizi pom.xml dosyamÄ±za ekliyoruz.

```xml
<dependency>
	<groupId>org.postgresql</groupId>
	<artifactId>postgresql</artifactId>
	<scope>runtime</scope>
</dependency>
<dependency>
	<groupId>org.springframework.kafka</groupId>
	<artifactId>spring-kafka</artifactId>
</dependency>
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-data-jpa</artifactId>
</dependency>
```

* Postgresql baÄŸlantÄ±sÄ±nÄ± ve gerekli Kafka baÄŸlantÄ±larÄ±nÄ± saÄŸlamak iÃ§in application.properties dosyamÄ±za property eklemesi gerÃ§ekleÅŸtiriyoruz.

```properties
mustafafindik.kafka.address = 127.0.0.1:9092
mustafafindik.kafka.group.id = kafka-group
mustafafindik.kafka.topic = kafka-topic

spring.datasource.url=jdbc:postgresql://localhost:5432/kafkapostgre
spring.datasource.username=postgres
spring.datasource.password=123456
spring.datasource.hikari.auto-commit=false
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
```

* Kafka'yÄ± dinlemek ve gelen veriyi tÃ¼ketmek (veritabanÄ±na kaydetmek gibi) iÃ§in KafkaConfiguration sÄ±nÄ±fÄ± oluÅŸturup kafkaListenerContainerFactory()
ve consumerFactory() metotlarÄ±mÄ±zÄ± oluÅŸturuyoruz.

```java
@Configuration
public class KafkaConfiguration {

    @Value("${mustafafindik.kafka.address}")
    private String kafkaAddress;
    @Value("${mustafafindik.kafka.group.id}")
    private String groupId;
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, User> kafkaListenerContainerFactory(){
        ConcurrentKafkaListenerContainerFactory<String, User> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
    @Bean
    public ConsumerFactory<String, User> consumerFactory() {
        Map<String,Object> consumer = new HashMap<>();
        consumer.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaAddress);
        consumer.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        consumer.put(JsonDeserializer.VALUE_DEFAULT_TYPE, User.class);
        consumer.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        consumer.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(consumer);
    }
}
```

* producer-service projemiz ile aynÄ± olacak ÅŸekilde modelimizi oluÅŸturup UserConsumer sÄ±nÄ±fÄ± iÃ§erisinde @KafkaListener ile topic ve groupId lerini belirterek Kafka'daki veriyi dinliyoruz. 

```java
@Slf4j
@Component
public class UserConsumer {
    private final UserService userService;
    public UserConsumer(UserService userService) {
        this.userService = userService;
    }
    @KafkaListener(
            topics = "${mustafafindik.kafka.topic}",
            groupId = "${mustafafindik.kafka.group.id}")
    public void userConsumer(User user){
        log.info("User received from Kafka pool. Username : {} , password : {}",
                user.getUsername(),
                user.getPassword());
        userService.saveUser(user);
    }
}
```

* Repository ve service sÄ±nÄ±flarÄ±mÄ±zÄ± oluÅŸturup veritabanÄ±na Kafka'daki veriyi kayÄ±t ediyoruz.

```java

@Slf4j
@Service
public class UserServiceImpl implements UserService{
    private final UserRepository userRepository;
    public UserServiceImpl(UserRepository userRepository) {
        this.userRepository = userRepository;
    }
    @Override
    public void saveUser(User user) {
        User saveUser = new User();
        saveUser.setUsername(user.getUsername());
        saveUser.setPassword(user.getPassword());
        userRepository.save(saveUser);
        log.info("User saved to the database : " + saveUser.toString());
    }
}
```

* localhost:2333/message pathine POST isteÄŸi attÄ±ÄŸÄ±mÄ±z zaman consumer-service deki console ekranÄ±nÄ±n log ekranÄ± bu ÅŸekildedir.
![image](https://user-images.githubusercontent.com/91599453/227889407-ac698cf3-b5cf-4152-845a-628fedba2480.png)

* pgadmine geldiÄŸimizde ise ilgili tabloya veriyi kaydettiÄŸini gÃ¶rebiliriz.

![image](https://user-images.githubusercontent.com/91599453/227889952-c83296bf-6ed8-4327-b6e7-5f19c85b3454.png)




