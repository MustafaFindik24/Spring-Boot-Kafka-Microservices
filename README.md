# ğŸ¯ Apache Kafka Nedir?

Kafka, herÅŸeyin veri olarak kabul edildiÄŸi bu dÃ¶nemde bize verilerin yÃ¶netimini kolaylaÅŸtÄ±ran, publish-subscriber tabanlÄ± bir daÄŸÄ±tÄ±k veri akÄ±ÅŸÄ± platformudur.

![image](https://user-images.githubusercontent.com/91599453/227554058-9150341a-4941-4d5b-bc5e-126084219ad5.png)

GeliÅŸmiÅŸ sistemlerin birbirleriyle yaptÄ±ÄŸÄ± veri akÄ±ÅŸÄ± sonucunda veri kaybÄ±nÄ±n Ã¶nlenmesi, verilerin en hÄ±zlÄ± ve sistemi en az etkileyecek ÅŸekilde gÃ¶nderimi konusunda Kafka bize kolaylÄ±k saÄŸlamaktadÄ±r. Veriler diske yazÄ±lÄ±r ve kafka cluster'larda kopyasÄ± oluÅŸturularak veri kaybÄ±nÄ±n Ã¶nÃ¼ne geÃ§er. GerÃ§ek zamana yakÄ±n bir ÅŸekilde veri akÄ±ÅŸÄ±nÄ± saÄŸlar. Ã–lÃ§eklenebilir olduÄŸundan sistemde herhangi bir kesinti yaÅŸanmaksÄ±zÄ±n sistemlerde aksama meydana gelmez. Uygulamalar arasÄ± platform desteÄŸi saÄŸlar, bu sayede farklÄ± platformlar arasÄ±nda veri akÄ±ÅŸÄ± saÄŸlanmÄ±ÅŸ olur. 

# ğŸ“Œ Kafka Terminolojileri 

- Publisher : Veriyi gÃ¶nderen uygulamadÄ±r.

- Subscriber: Veriyi alan uygulamadÄ±r.

- Producer  : Bir veya birden fazla topice veri gÃ¶nderen birimdir.

- Consumer  : Bir veya birden fazla topicten veri okuyabilen birimdir.

- Topic     : Verilerin saklandÄ±ÄŸÄ± ve listelenebildiÄŸi bir kategori. VeritabanÄ±ndaki tablonun karÅŸÄ±lÄ±ÄŸÄ±dÄ±r.

- Partition : Veriyi tek bir yerde tutmak yerine farklÄ± dizinlerde tutmak performans ve veri kaybÄ±nÄ±n Ã¶nlenmesi aÃ§Ä±sÄ±ndan daha verimlidir. Topicler bir veya birden fazla ÅŸekilde parÃ§alardan (partition) oluÅŸurlar. Bu ÅŸekilde bir topicdeki veriler birden fazla sunucuda tutulabilir.

![image](https://user-images.githubusercontent.com/91599453/227864593-bae505df-8f22-41ae-abe9-1906c0996cbf.png)

- Broker    : Birden fazla partitionÄ±n birlikte oluÅŸturduÄŸu yapÄ±ya broker denir. Her bir Kafka sunucusuna (cluster) broker adÄ± verilir.

- Cluster   : Kafka daÄŸÄ±tÄ±k bir sistemdir. Birden fazla sunucudan oluÅŸur ve verileri farklÄ± sunucularda (cluster) tutabilir. Bu sayede daha hÄ±zlÄ± ve daha performanslÄ± veri akÄ±ÅŸÄ± saÄŸlanÄ±r.

- Offset    : KafkanÄ±n bir subscriber (consumer) gÃ¶nderdiÄŸi son mesajÄ±n numarasÄ±dÄ±r.

- Zookeeper : Kafka cluster'da topic ve verilerin listesini saklayan, nodelarÄ±n durumunu izleyen; uygulamaya bir broker eklendiÄŸi zaman veya Ã§alÄ±ÅŸmadÄ±ÄŸÄ±, bir problem oluÅŸtuÄŸu zaman publisher (producer) ve subscriber (consumer) bilgilendiren bir servis olarak tanÄ±mlanabilir. Kafka, metadata bilgilerini saklamak iÃ§in Zookeeper'Ä± kullanmaktadÄ±r. Bu sebeple Kafka ile kullanÄ±mÄ± zorunludur.

# ğŸ“Œ Apache Kafka ve Spring Boot

* Bir Spring Boot projesi oluÅŸturup Kafka kullanÄ±mÄ± iÃ§in pom.xml dosyamÄ±zÄ±n iÃ§erisine Kafka dependency eklenir.

``` xml

<dependency>
	<groupId>org.springframework.kafka</groupId>
	<artifactId>spring-kafka</artifactId>
</dependency>

```

* Kafka'yÄ± Docker Ã¼zerinde Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z. Bunun iÃ§in docker-compose dosyasÄ± oluÅŸturup gerekli imagelarÄ± ekleyip ilgili containerlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±yoruz.

```yml

version: '3.8'
services:

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:5.4.9
    restart: always
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - my-network

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:6.0.9
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_ADVERTISED_HOST_NAME:
    networks:
      - my-network

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: always
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKER_CONNECT: kafka:29092
    networks:
      - my-network

networks:
  my-network:
    driver: bridge
    
```

* Kafkada producer ve consumer sÃ¼reÃ§lerinden bahsetmiÅŸtik. Tek bir projede bÃ¼tÃ¼n sÃ¼reÃ§leri kontrol etmek yerine hem producer hem de consumer iÃ§in farklÄ± projeler oluÅŸturup microservice mimarisi mantÄ±ÄŸÄ±na gÃ¶re uygulamamÄ±zÄ± Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z. 

application.properties dosyamÄ±zda server portunu, logging iÃ§in log seviyesini ve kafkanÄ±n adresini, deÄŸerini ve topic ismini belirtiyoruz.
```properties
server.port=2333

logging.level.root= INFO

mustafafindik.kafka.address = 127.0.0.1:9092
mustafafindik.kafka.group.id = kafka-group
mustafafindik.kafka.topic = kafka-topic
```

* Ä°lk olarak producer-service projemizde veriyi Ã¼retip kafkaya atamak iÃ§in bazÄ± configurationlar gerekli. Bunu config package Ä± altÄ±nda oluÅŸturup Spring IOC containerÄ±na atamak iÃ§in bean olarak belirtiyoruz. application.properties sÄ±nÄ±fÄ±nda belirttiÄŸimiz value larÄ± ekleyip veriyi gÃ¶ndermek iÃ§in kafkaTemplate sÄ±nÄ±fÄ±nÄ±, veriyi Ã¼retmek iÃ§inde producerFactory sÄ±nÄ±fÄ±nÄ± belirtiyoruz.

```java
@Configuration
public class KafkaConfiguration {

    @Value("${mustafafindik.kafka.address}")
    private String kafkaAddress;
    
    @Value("${mustafafindik.kafka.group.id}")
    private String groupId;
    
    @Bean
    public KafkaTemplate<String, User> kafkaTemplate(){
        return new KafkaTemplate<>(producerFactory());
    }
    @Bean
    public ProducerFactory producerFactory(){
        Map<String,Object> producer = new HashMap<>();
        producer.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaAddress);
        producer.put(JsonSerializer.ADD_TYPE_INFO_HEADERS,true);
        producer.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        producer.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,JsonSerializer.class);
        return new DefaultKafkaProducerFactory(producer);
    }
}
```
* Modelimizi oluÅŸturup Kafka'ya veri gÃ¶nderimini saÄŸlamak iÃ§in KafkaProducer sÄ±nÄ±fÄ±nÄ± oluÅŸturduk. KafkaTemplate sÄ±nÄ±fÄ±nÄ± inject edip send() metoduyla veri gÃ¶nderimi iÃ§in ortam hazÄ±rlandÄ±.

```java
@Component
public class KafkaProducer {
    
    private final KafkaTemplate<String, User> kafkaTemplate;

    public KafkaProducer(KafkaTemplate<String, User> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    public void userProducer(User user){
        kafkaTemplate.send("${mustafafindik.kafka.topic}", UUID.randomUUID().toString(),user);
    }
}
```
* Service sÄ±nÄ±fÄ±mÄ±zÄ± oluÅŸturup KafkaProducer sÄ±nÄ±fÄ±nÄ± inject edip Kafka'ya veri gÃ¶nderimi iÃ§in metot oluÅŸturduk ve KafkaProducer sÄ±nÄ±fÄ±ndaki metodu kullandÄ±k.

```java
@Service
public class UserServiceImpl implements UserService{
    private final KafkaProducer kafkaProducer;

    public UserServiceImpl(KafkaProducer kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }
    @Override
    public void createUser(User user) {
        User saveUser = new User();
        saveUser.setUsername(saveUser.getUsername());
        saveUser.setPassword(saveUser.getPassword());
        kafkaProducer.userProducer(saveUser);
    }
}
```

* Controller sÄ±nÄ±fÄ±nda post isteÄŸi iÃ§in metot oluÅŸturduk ve logunu gÃ¶rebilmek iÃ§in console ekranÄ±na info bastÄ±rdÄ±k.

```java
@Slf4j
@RestController
@RequestMapping("/message")
public class UserController {

    @Value("${mustafafindik.kafka.topic}")
    private String topic;
    private final KafkaTemplate<String, User> kafkaTemplate;

    public UserController(KafkaTemplate<String, User> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    @PostMapping
    public void sendMessage(@RequestBody User user){
        kafkaTemplate.send(topic, UUID.randomUUID().toString(), user);
        log.info("User class send to the queue : " + user);
    }
}
```




















